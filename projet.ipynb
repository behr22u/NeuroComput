{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brian2 import *\n",
    "#from brian2tools import *\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SIMULATION PARAMETERS\n",
    "\n",
    "prefs.codegen.target = 'numpy'\n",
    "# the numerical resolution method that shall be used by Brian\n",
    "diff_method = \"euler\"\n",
    "time_step = 0.01 * ms\n",
    "defaultclock.dt = time_step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## NEURONS AND SYNAPSES PARAMETERS ################################## \n",
    "\n",
    "######### (A) Neuronal parameters, used in (1) and (4) ########\n",
    "\n",
    "# time constants\n",
    "tau_m = 1.0 * ms # ok\n",
    "tau_m_inh = 0.5 * ms # ok\n",
    "# membrane potential after reset\n",
    "v_rest = 0.0 # ok\n",
    "# spiking threshold\n",
    "theta_u = 0.5 # ok\n",
    "theta_inh = 0.01 # ok\n",
    "\n",
    "########## (B) Synaptic parameters, used in (2) and (3) for different synapse types ######### \n",
    "\n",
    "# temporal layer to som layer (u to v)\n",
    "tau_r_afferent = 0.2 * ms\n",
    "tau_f_afferent = 1.0 * ms\n",
    "\n",
    "# temporal layer (u to inh exc, u to inh inh, inh to u)\n",
    "tau_r_exc = 0.4 * ms\n",
    "tau_f_exc = 2.0 * ms\n",
    "tau_r_inh = 0.2 * ms\n",
    "tau_f_inh = 1.0 * ms\n",
    "tau_r_inh2u = 1.0 * ms\n",
    "tau_f_inh2u = 5.0 * ms\n",
    "\n",
    "########## (C) Maximum magnitudes of synaptic connection strength ########## poids synaptique\n",
    "w_syn_u2inh_exc_max = 1.0\n",
    "w_syn_u2inh_inh_max = 1.0\n",
    "w_syn_inh2u_max = 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReceptiveField:\n",
    "    # Parameter used in standard deviation definition\n",
    "    gamma = 1.5\n",
    "\n",
    "    def __init__(self, bank_size = 10, I_min =0.05 , I_max =0.95 ):\n",
    "        # number of units used to encode a real value  \n",
    "        self.bank_size = bank_size\n",
    "        # field_mu corresponds to the mean of the gaussian and shall be a numpy array \n",
    "        self.field_mu = np.zeros(bank_size)\n",
    "        for i in range (bank_size): \n",
    "            mui = I_min + (((2*(i+1)-2)/2)*(I_max - I_min)/(bank_size-1))\n",
    "            self.field_mu[i] = mui\n",
    "        # field_sigma corresponds to the standard deviation of the gaussian and shall be a float\n",
    "        self.field_sigma = 1/self.gamma * (I_max - I_min)\n",
    "        \n",
    "    def float_to_potential(self, input_vector):\n",
    "        try:\n",
    "            input_vector = input_vector.reshape((input_vector.shape[0], 1))\n",
    "            #self.field_mu = self.field_mu.reshape((self.field_mu.shape[0], 1))\n",
    "            \n",
    "        except Exception as exc:\n",
    "            print(\"Exception: {0}\\nObject shape: {1}\".format(repr(exc), input_vector.shape))\n",
    "            exit(1)\n",
    "            \n",
    "        #résultat de f(x)\n",
    "        result = e**(-((input_vector - self.field_mu)**2) /(2*self.field_sigma**2)) ### VERIF\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = ReceptiveField()\n",
    "inp_size = 2\n",
    "inp_vector = np.random.uniform(0,1,inp_size)\n",
    "inp_vector = np.array([0.2,0.6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5999999999999999"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.field_sigma  # 0.59999999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96923323, 0.9965338 , 0.9965338 , 0.96923323, 0.91685536,\n",
       "        0.84354765, 0.7548396 , 0.65695557, 0.55610088, 0.45783336],\n",
       "       [0.65695557, 0.7548396 , 0.84354765, 0.91685536, 0.96923323,\n",
       "        0.9965338 , 0.9965338 , 0.96923323, 0.91685536, 0.84354765]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_potentials = rf.float_to_potential(inp_vector) \n",
    "inp_potentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## notes séance 06/02\n",
    "c'est le temps d'émission qui encode l'information \n",
    "c'est une propagation \n",
    "\n",
    "Tous les neurones sont les mêmes dans u et v c'est les mêmes modèles mais avec des paramètre différents \n",
    "fèche exitateur\n",
    "flèche plate inhibiteur \n",
    "\n",
    "c'est dans le modèle des synapse qu'on mettra les fonctions alpha \n",
    "u = à la somme des poids des synapses \n",
    "w le poids synaptique\n",
    "\n",
    "fonctions alpha les règles des synapses \n",
    "\n",
    "pas obligé de faire l'apprentissage dans un premier temps \n",
    "\n",
    "eq 5 : adapter les poids synaptiques\n",
    "    --> en fonction de ce qui est reçu on applique une règle ou l'autre \n",
    "    \n",
    "    \n",
    "summed variable sert pour l'eq 4 \n",
    "\n",
    "eq 6 : implémenter la différence de gaussienne --> partie 5 de l'aide\n",
    "\n",
    "eq 7 réduire le rayon au cours du temps\n",
    "    T n'est pas donné (essayer 10 on peut jouer avec)\n",
    "    n non plus n=1 on peut essayer de le faire varier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# à adapter, peret de calculer la distance toroidale\n",
    "# permet de calculer le vecteur d'entrée de u\n",
    "# implémenter le noyer d'interraction pour la pop v\n",
    "def toroidalDistance(x1,x2):\n",
    "    dx = np.abs(x1 - x2)\n",
    "    tor_dist = np.where(dx < 0, dx, 1.0 - dx)\n",
    "    return tor_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_scope()\n",
    "##### sans inh #####\n",
    "u_layer_neuron_equ = '''\n",
    "I_ext : 1\n",
    "\n",
    "# membrane potential of u layer \n",
    "dv/dt = (-v +I_ext) / tau_m:1\n",
    "'''\n",
    "N = 10 * inp_size\n",
    "u_layer = NeuronGroup(N,u_layer_neuron_equ, threshold='v>0.5', reset='v=0', method='exact')\n",
    "\n",
    "u_layer.I_ext = inp_potentials.flatten()\n",
    "\n",
    "spikemon = SpikeMonitor(u_layer, variables='v')\n",
    "run(10*ms)\n",
    "plot(spikemon.t/ms, spikemon.i, '.k')\n",
    "xlabel('Time (ms)')\n",
    "ylabel('Neuron index');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_scope()\n",
    "##### sans inh #####\n",
    "u_layer_neuron_equ = '''\n",
    "I_ext : 1\n",
    "\n",
    "# membrane potential of u layer \n",
    "dv/dt = (-v +I_ext) / tau_m:1\n",
    "'''\n",
    "\n",
    "\n",
    "inhibition_neuron_equ = '''\n",
    "    # inhibitory synapses to inh neuron : alpha functions\n",
    "    ds_u2inh_inh/dt = (-s_u2inh_inh)/tau_r_inh:1\n",
    "    dI_u2inh_inh/dt = (s_u2inh_inh-I_u2inh_inh)/tau_f_inh :1\n",
    "\n",
    "    # exitatory synapses to inh neuron : alpha functions\n",
    "    ds_u2inh_ext/dt = (-s_u2inh_ext)/tau_r_exc:1\n",
    "    dI_u2inh_ext/dt = (s_u2inh_ext-I_u2inh_ext)/tau_f_exc :1\n",
    "    \n",
    "    # membrane potential of inh neuron\n",
    "    dv/dt = (-v + I_u2inh_ext - I_u2inh_inh) / tau_m_inh:1\n",
    "'''\n",
    "    \n",
    "N = 10 * inp_size\n",
    "u_layer = NeuronGroup(N,u_layer_neuron_equ, threshold='v>0.5', reset='v=0', method='exact')\n",
    "\n",
    "inhibition_neuron = NeuronGroup(1,inhibition_neuron_equ, threshold='v>0.5', reset='v=0', method='exact')\n",
    "\n",
    "# N de U = 10* input size\\n\",\n",
    "# la sortie de de U doit être 1dim de taille 20\n",
    "# I_ext  doit être 1 dim --> funct flatten()\n",
    "u_layer.I_ext = inp_potentials.flatten()\n",
    "\n",
    "model_synapse_inh2u_inhibition = '''\n",
    "w_syn : 1\n",
    "'''    \n",
    "on_pre_synapse_inh2u_inhibition = '''\n",
    "s_inh2u += w_syn\n",
    "'''\n",
    "\n",
    "model_synapse_u2inh_exitation = '''\n",
    "w_syn : 1\n",
    "'''\n",
    "on_pre_synapse_u2inh_exitation = '''\n",
    "s_u2inh_ext += w_syn\n",
    "'''\n",
    "\n",
    "model_synapse_u2inh_inhibition = '''\n",
    "w_syn : 1\n",
    "'''\n",
    "on_pre_synapse_u2inh_inhibition = '''\n",
    "s_u2inh_inh += w_syn\n",
    "'''\n",
    "\n",
    "\n",
    "#définir le modèle de synapse\n",
    "u2inh_exitation = Synapses(u_layer, \n",
    "                            inhibition_neuron,\n",
    "                            model_synapse_u2inh_exitation,\n",
    "                            on_pre=on_pre_synapse_u2inh_exitation)\n",
    "u2inh_inhibition = Synapses(u_layer, \n",
    "                            inhibition_neuron,\n",
    "                            model_synapse_u2inh_inhibition,\n",
    "                            on_pre=on_pre_synapse_u2inh_inhibition)\n",
    "\n",
    "\n",
    "\n",
    "## faire les connextions \n",
    "u2inh_exitation.connect()\n",
    "u2inh_inhibition.connect()\n",
    "#inh2u_inhibition.connect()\n",
    "\n",
    "## pour l'instant poids synaptiques constants (je sais pas si ça changera ni comment)\n",
    "u2inh_exitation.w_syn = w_syn_u2inh_exc_max\n",
    "u2inh_inhibition.w_syn = w_syn_u2inh_inh_max\n",
    "#inh2u_inhibition.w_syn = w_syn_inh2u_max\n",
    "spikemon = SpikeMonitor(u_layer, variables='v')\n",
    "run(10*ms)\n",
    "plot(spikemon.t/ms, spikemon.i, '.k')\n",
    "xlabel('Time (ms)')\n",
    "ylabel('Neuron index');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Parties retirée pour faire étape par étapes\n",
    "\n",
    "\n",
    "u_layer_neuron_equ = '''\n",
    "    I_ext : 1\\n\n",
    "    \n",
    "    # inhibitory synapses to u layer : alpha functions\n",
    "    ds_inh2u/dt = (-s_inh2u)/tau_r_inh2u:1\\n\n",
    "    dI_inh2u/dt = (s_inh2u-I_inh2u)/tau_f_inh2u :1\\n\n",
    "    \n",
    "    # membrane potential of u layer \\n\n",
    "    dv/dt = (-v +I_ext - I_inh2u) / tau_m:1\\n\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "inh2u_inhibition = Synapses(inhibition_neuron, \n",
    "                            u_layer, \n",
    "                            model_synapse_inh2u_inhibition, \n",
    "                            on_pre=on_pre_synapse_inh2u_inhibition )\n",
    "\n",
    "\n",
    "inhibition_neuron_equ = '''\n",
    "    # inhibitory synapses to inh neuron : alpha functions\n",
    "    ds_u2inh_inh/dt = (-s_u2inh_inh)/tau_r_inh:1\n",
    "    dI_u2ihn_inh/dt = (s_u2inh_inh-I_u2inh_inh)/tau_f_inh :1\n",
    "\n",
    "    # exitatory synapses to inh neuron : alpha functions\n",
    "    ds_u2inh_ext/dt = (-s_u2inh_ext)/tau_r_exc:1\n",
    "    dI_u2inh_ext/dt = (s_u2inh_ext-I_u2inh_ext)/tau_f_exc :1\n",
    "    \n",
    "    # membrane potential of inh neuron\n",
    "    dv/dt = (-v + I_u2inh_ext - I_u2inh_inh) / tau_m_inh:1\n",
    "'''\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partie copiée de la partie 6 aide\n",
    "net_model = Network(collect())\n",
    "net_model.store()\n",
    "\n",
    "for epoch in range (nb_epoch):\n",
    "    np.random.shuffle(dataset)\n",
    "    for vector in enumerate(dataset):\n",
    "        for oscil in range(nb_oscil):\n",
    "            net_model.restore()\n",
    "            potential_input = rf.float_to_membrane_potential(vector)\n",
    "            u_layer.I_ext = potential_input.flatten()\n",
    "            net_model.run(oscillation_period)\n",
    "            net_model.store()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U va convertir une valeure en motif spacio temporel \n",
    "l'apprentissage se situe entre U et V \n",
    "si y a pas inh : U se désincronise \n",
    "--> but: ne pas perdre le motif, on veut que le cycle se reproduise à l'identique \n",
    "    Inh va détecter la fin de la séquence offsetdetector (il y a aussi onset detector), en offset il va inhibier toutes les dissonances pour qu'il y ai toujours le motif \n",
    "    \n",
    "Pour le renforcement : on prend le signe de delta w \n",
    "\n",
    "I : tableau 2 dimentions normalisé (entre 0 et 1)\n",
    "On veut encoder ces valeures là de façon spacio-temporelle avec le temps d'émiion des spikes\n",
    "On va donc la représenter avec une banque de 10 neurones \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
